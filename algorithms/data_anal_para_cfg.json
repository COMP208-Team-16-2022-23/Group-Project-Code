[
  {
    "section_name": "Descriptive statistics",
    "code_name": "descriptive_statistics",
    "algorithms": [
      {
        "name": "Normality test",
        "code_name": "normality_test",
        "description": "A normality test is any statistical test for determining whether a data sample comes from a normal distribution.",
        "link": "https://en.wikipedia.org/wiki/Normality_test",
        "variables": [
          {
            "name": "variable",
            "description": "The variable to test for normality.",
            "type": "single_select"
          }
        ],
        "parameters": [
        ]
      }
    ]
  },
  {
    "section_name": "Questionaire Analysis",
    "code_name": "questionaire_analysis",
    "algorithms": [
      {
        "name": "Reliability Analysis",
        "code_name": "reliability_analysis",
        "description": "Reliability analysis is mainly used to examine the stability and consistency of the results measured by the scale in the questionnaire, that is, to test whether the scale samples in the questionnaire are reliable and credible. The scale question type is the option of the question, which is set according to the level of statement. For example, our love for mobile phones has changed from very fond of to dislike. The most famous scale in the scale is the Likert 5-level scale. The options of this scale are mainly divided into \"strongly agree\", \"agree\", \"not sure\", \"disagree\", \"very disagree\"” five answers, recorded as 5, 4, 3, 2, 1 respectively.",
        "link": "https://en.wikipedia.org/wiki/Normality_test",
        "variables": [
          {
            "name": "variables",
            "description": "The variables to conduct the reliability analysis.",
            "type": "multi_select"
          }
        ],
        "parameters": [
          {
            "name": "Analytical method",
            "code_name": "reliability_analysis",
            "type": "select",
            "options": [
              "Cronbach's α",
              "Split-half Reliability"
            ],
            "description": "Cronbach's α reliability coefficient is the most commonly used reliability coefficient, α coefficient evaluation\nThe most important thing is the consistency between the scores of each item in the scale, which belongs to the internal consistency coefficient.\nThe split-half reliability method divides the survey items into two halves and calculates the correlation between the scores of the two halves.\ncoefficient to estimate the reliability of the entire scale. When conducting half-way reliability analysis, such as\nIf the scale contains anti-meaning items, the scores of anti-meaning items should be reversed first,\nIn order to ensure the consistency of the scoring direction of each item, all the items are divided into odd-even or former\nDivide into two halves that are as equal as possible"
          }
          ]
      }
    ]
  },
  {
    "section_name": "ML Classification",
    "code_name": "ml_classification",
    "algorithms": [
      {
        "name": "K-Nearest Neighbors",
        "code_name": "knn_classification",
        "description": "K-Nearest Neighbors is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions).",
        "link": "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm",
        "variables": [
          {
            "name": "features",
            "description": "The variables to use as features.",
            "type": "multi_select"
          },
          {
            "name": "target",
            "description": "The variable to use as the target.",
            "type": "single_select"
          }
        ],
        "parameters": [
          {
            "name": "Data shuffling",
            "code_name": "shuffle",
            "type": "checkbox",
            "description": "Reshuffle the data to re-segment the data according to the training.",
            "default": "checked"
          },
          {
            "name": "Training ratio",
            "code_name": "train_ratio",
            "type": "number",
            "description": "The ratio of the data to use for training.",
            "default": 0.8
          },
          {
            "name": "Cross validation",
            "code_name": "cross_validation",
            "type": "select",
            "options": [
              "None",
              "10-fold",
              "5-fold",
              "4-fold",
              "3-fold",
              "2-fold"
            ],
            "description": "The cross validation method to use.",
            "default": "None"
          },
          {
            "name": "Number of neighbors",
            "code_name": "n_neighbors",
            "type": "number",
            "description": "Number of neighbors to use by default for kneighbors queries.",
            "default": 5
          },
          {
            "name": "Weights",
            "code_name": "weights",
            "type": "select",
            "options": [
              "uniform",
              "distance"
            ],
            "description": "Weight function used in prediction. Possible values: 'uniform': uniform weights. All points in each neighborhood are weighted equally. 'distance': weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.",
            "default": "uniform"
          },
          {
            "name": "Algorithm",
            "code_name": "algorithm",
            "type": "select",
            "options": [
              "auto",
              "ball_tree",
              "kd_tree",
              "brute"
            ],
            "description": "Algorithm used to compute the nearest neighbors: 'ball_tree' will use BallTree, 'kd_tree' will use KDTree, 'brute' will use a brute-force search. 'auto' will attempt to decide the most appropriate algorithm based on the values passed to fit method. Note: fitting on sparse input will override the setting of this parameter, using brute force.",
            "default": "auto"
          },
          {
            "name": "Leaf size",
            "code_name": "leaf_size",
            "type": "number",
            "description": "Leaf size passed to BallTree or KDTree. This can affect the speed of the construction and query, as well as the memory required to store the tree. The optimal value depends on the nature of the problem.",
            "default": 30
          },
          {
            "name": "P",
            "code_name": "p",
            "type": "number",
            "description": "Parameter for the Minkowski metric from sklearn.metrics.pairwise.pairwise_distances. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.",
            "default": 2
          }
        ]
      },
      {
        "name": "SVM classification",
        "code_name": "svm_classification",
        "description": "Support vector machine (SVM) is a class of generalised linear classifiers that perform binary classification of data in a supervised learning fashion, with a decision boundary that is a maximum margin hyperplane solved for the learned samples.",
        "link": "https://en.wikipedia.org/wiki/Support_vector_machine",
        "variables": [
          {
            "name": "features",
            "description": "The variables to use as features.",
            "type": "multi_select"
          },
          {
            "name": "target",
            "description": "The variable to use as the target.",
            "type": "single_select"
          }
        ],
        "parameters": [
          {
            "name": "Data shuffling",
            "code_name": "shuffle",
            "type": "checkbox",
            "description": "Reshuffle the data to re-segment the data according to the training.",
            "default": "checked"
          },
          {
            "name": "Training ratio",
            "code_name": "train_ratio",
            "type": "number",
            "description": "The ratio of the data to use for training.",
            "default": 0.7
          },
          {
            "name": "Cross validation",
            "code_name": "cross_validation",
            "type": "select",
            "options": [
              "None",
              "10-fold",
              "5-fold",
              "4-fold",
              "3-fold",
              "2-fold"
            ],
            "description": "The cross validation method to use.",
            "default": "None"
          },
          {
            "name": "penalty coefficient",
            "code_name": "C",
            "type": "number",
            "description": "The higher the value of the penalty coefficient, the more intolerant the error is.",
            "default": 1.00
          },
          {
            "name": "Kernel algorithm",
            "code_name": "kernel",
            "type": "select",
            "options": [
              "linear",
              "poly",
              "rbf",
              "sigmoid"
            ],
            "description": "The \"linear\" kernel function is suitable for linearly divisible data sets, the \"poly\" kernel function is suitable for non-linear data sets with simple distribution patterns, the \"rbf\" kernel function is suitable for complex non-linear data sets, and the \"sigmoid\" kernel function is suitable for handling binary classification problems.",
            "default": "rbf"
          },
          {
            "name": "Error convergence conditions",
            "code_name": "tol",
            "type": "number",
            "description": "Error value size for stopping training",
            "default": 0.001
          },
          {
            "name": "Maximum number of iterations",
            "code_name": "max_iter",
            "type": "number",
            "description": "If the algorithm does not converge, the computation stops when the maximum number of iterations is reached.",
            "default": 1000
          }
        ]
      },
      {
        "name": "Decision Tree",
        "code_name": "decision_tree",
        "description": "A decision tree is a flowchart-like structure in which each internal node represents a test on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes).",
        "link": "https://en.wikipedia.org/wiki/Decision_tree_learning",
        "variables": [
          {
            "name": "features",
            "description": "The variables to use as the features.",
            "type": "multi_select"
          },
          {
            "name": "target",
            "description": "The variable to use as the target.",
            "type": "single_select"
          }
        ],
        "parameters": [
          {
            "name": "Max depth",
            "code_name": "max_depth",
            "type": "number",
            "description": "The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain.",
            "default": "gini"
          }
        ]
      }
    ]
  }
]
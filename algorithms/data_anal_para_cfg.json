[
  {
    "section_name": "Descriptive statistics",
    "code_name": "descriptive_statistics",
    "algorithms": [
      {
        "name": "Normality test",
        "code_name": "normality_test",
        "description": "A normality test is any statistical test for determining whether a data sample comes from a normal distribution.",
        "link": "https://en.wikipedia.org/wiki/Normality_test",
        "variables": [
          {
            "name": "variables",
            "description": "The variables to test for normality.",
            "type": "multi_select"
          }
        ],
        "parameters": [
        ]
      }
    ]
  },
  {
    "section_name": "ML Classification",
    "code_name": "ml_classification",
    "algorithms": [
      {
        "name": "K-Nearest Neighbors",
        "code_name": "knn",
        "description": "K-Nearest Neighbors is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions).",
        "link": "https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm",
        "variables": [
          {
            "name": "features",
            "description": "The variables to use as features.",
            "type": "multi_select"
          },
          {
            "name": "target",
            "description": "The variable to use as the target.",
            "type": "single_select"
          }
        ],
        "parameters": [
          {
            "name": "Number of neighbors",
            "code_name": "n_neighbors",
            "type": "number",
            "description": "Number of neighbors to use by default for kneighbors queries.",
            "default": 5
          }
        ]
      },
      {
        "name": "Decision Tree",
        "code_name": "decision_tree",
        "description": "A decision tree is a flowchart-like structure in which each internal node represents a test on an attribute, each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes).",
        "link": "https://en.wikipedia.org/wiki/Decision_tree_learning",
        "variables": [
          {
            "name": "features",
            "description": "The variables to use as the features.",
            "type": "multi_select"
          },
          {
            "name": "target",
            "description": "The variable to use as the target.",
            "type": "single_select"
          }
        ],
        "parameters": [
          {
            "name": "Max depth",
            "code_name": "max_depth",
            "type": "number",
            "description": "The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain.",
            "default": "gini"
          }
        ]
      }
    ]
  }
]